SSE = sum((Zchapeau - Z_i_barre)^2)
SST = sum((Z_i - Z_i_barre)^2)
R2 = 1- SSE/SST
X_i_barre = mean(X_i)
Z_i_barre = mean(Z_i)
beta1chapeau = sum((X_i - X_i_barre) * (Z_i - Z_i_barre)) / sum((X_i - X_i_barre)^2)
beta0chapeau = Z_i_barre - beta1chapeau*X_i_barre
Zchapeau = beta0chapeau + beta1chapeau*X_i
SSE = sum((Zchapeau - Z_i_barre)^2)
SST = sum((Z_i - Z_i_barre)^2)
R2 = SSE/SST
prediction = lm(Z_i~X_i)
R2_lm = summary.lm(prediction)$r.squared
beta0 = coef(prediction)[1]
beta1 = coef(prediction)[2]
plot(X_i, Z_i, pch = 19, col = "blue", main = "Logarithme du nombre de bactéries survivantes en fonction du temps d'exposition", xlab = "Temps en minutes", ylab = "Nombre de bactéries survivantes")
lines(X_i, beta0 + beta1*Z_i)
plot(X_i, Z_i, pch = 19, col = "blue", main = "Logarithme du nombre de bactéries survivantes en fonction du temps d'exposition", xlab = "Temps en minutes", ylab = "Nombre de bactéries survivantes")
lines(X_i, beta0 + beta1*X_i)
plot(X_i, Z_i, pch = 19, col = "green", main = "Logarithme du nombre de bactéries survivantes en fonction du temps d'exposition", xlab = "Temps en minutes", ylab = "Nombre de bactéries survivantes")
lines(X_i, beta0 + beta1*X_i, lwd = 2, col = "red")
plot(X_i, Z_i, pch = 19, col = "yellow", main = "Logarithme du nombre de bactéries survivantes en fonction du temps d'exposition", xlab = "Temps en minutes", ylab = "Nombre de bactéries survivantes")
lines(X_i, beta0 + beta1*X_i, lwd = 2, col = "purple")
plot(X_i, Z_i, pch = 19, col = "red", main = "Logarithme du nombre de bactéries survivantes en fonction du temps d'exposition", xlab = "Temps en minutes", ylab = "Nombre de bactéries survivantes")
lines(X_i, beta0 + beta1*X_i, lwd = 2, col = "purple")
plot(X_i, Z_i, pch = 19, col = "red", main = "Logarithme du nombre de bactéries survivantes en fonction du temps d'exposition", xlab = "Temps en minutes", ylab = "Nombre de bactéries survivantes")
lines(X_i, beta0 + beta1*X_i, lwd = 2, col = "blue")
plot(X_i, Z_i, pch = 19, col = "red", main = "Logarithme du nombre de bactéries survivantes en fonction du temps d'exposition", xlab = "Temps en minutes", ylab = "Nombre de bactéries survivantes")
lines(X_i, beta0 + beta1*X_i, lwd = 2, col = "blue")
legend("topright", legend = "Droite de regréssion", col = "blue", lwd = 2)
knitr::opts_chunk$set(echo = TRUE)
```{r}
rm(list=ls())
X_i = c(10, 10, 10, 12, 12, 12, 14, 14, 14, 16, 16, 16, 18, 18, 18, 20, 20, 20)
Y_i = c(16, 12, 11, 16, 17, 13, 18, 14, 13, 21, 12, 17, 25, 18, 21, 20, 26, 23)
X_i = c(10, 10, 10, 12, 12, 12, 14, 14, 14, 16, 16, 16, 18, 18, 18, 20, 20, 20)
Y_i = c(16, 12, 11, 16, 17, 13, 18, 14, 13, 21, 12, 17, 25, 18, 21, 20, 26, 23)
plot(X_i, Y_i, main = "Nombre de bactéries en fonction de la température", xlab = "Température en °C", ylab = "Nombre de bactéries", type = "l", col = "red", lwd = 2)
X_i = c(10, 10, 10, 12, 12, 12, 14, 14, 14, 16, 16, 16, 18, 18, 18, 20, 20, 20)
Y_i = c(16, 12, 11, 16, 17, 13, 18, 14, 13, 21, 12, 17, 25, 18, 21, 20, 26, 23)
plot(X_i, Y_i, main = "Nombre de bactéries en fonction de la température", xlab = "Température en °C", ylab = "Nombre de bactéries")
X_i = c(10, 10, 10, 12, 12, 12, 14, 14, 14, 16, 16, 16, 18, 18, 18, 20, 20, 20)
Y_i = c(16, 12, 11, 16, 17, 13, 18, 14, 13, 21, 12, 17, 25, 18, 21, 20, 26, 23)
plot(X_i, Y_i, main = "Nombre de bactéries en fonction de la température", xlab = "Température en °C", ylab = "Nombre de bactéries", type = "l", col = "red", lwd = 2)
X_i_barre = mean(X_i)
Y_i_barre = mean(Y_i)
beta1chapeau = sum((X_i - X_i_barre)*(Y_i - Y_i_barre))/sum((X_i-X_i_barre)^2)
beta0chapeau = Y_i_barre - X_i_barre*beta1chapeau
Ychapeau = beta0chapeau + beta1chapeau*X_i
SSE = sum((Ychapeau - Y_i_barre)^2)
SST = sum((Y_i - Y_i_barre)^2)
R2 = SSE/SST
prediction = lm(Y_i~X_i)
prediction = lm(Y_i~X_i)
beta0 = coef(prediction)[1]
beta1 = coef(prediction)[2]
View(prediction)
prediction = lm(Y_i~X_i)
beta0 = coef(prediction)[1]
beta1 = coef(prediction)[2]
sigma2 = sum((Y_i-beta0 - beta1*X_i)^2)/(length(X_i)-2)
View(prediction)
t_statistic <- (beta1 - 20000) / sqrt(sigma2 / sum((X_i-mean(X_i))^2))
p_value <- 2*pt(-abs(t_statistic), df = length(X_i) - 2)
p_value
X_19 = 19
Y_19 = beta0 + beta1*X_19
SE = sqrt(sigma2 * (1/length(X_i) + (X_19-X_i_barre)^2/sum((X_i-X_i_barre)^2)))
borne = qt(0.95, df = length(X_i)-2)*SE
borneInf = Y_19 - borne
borneSup = Y_19 + borne
X_19 = 19
Y_19 = beta0 + beta1*X_19
SE = sqrt(sigma2 * (1/length(X_i) + (X_19-X_i_barre)^2/sum((X_i-X_i_barre)^2)))
borne = qt(0.95, df = length(X_i)-2)*SE
borneInf = Y_19 - borne
borneSup = Y_19 + borne
X_19 = 19
Y_19 = beta0 + beta1*X_19
SE = sqrt(sigma2 * (1/length(X_i) + (X_19-X_i_barre)^2/sum((X_i-X_i_barre)^2)))
borne = qt(0.95, df = length(X_i)-2)*SE
borneInf = Y_19 - borne
borneSup = Y_19 + borne
plot(X_i, Y_i, main = "Nombre de bactéries en fonction de la température", xlab = "Température en °C", ylab = "Nombre de bactéries")
lines(borneInf)
X_19 = 19
Y_19 = beta0 + beta1*X_19
SE = sqrt(sigma2 * (1/length(X_i) + (X_19-X_i_barre)^2/sum((X_i-X_i_barre)^2)))
borne = qt(0.95, df = length(X_i)-2)*SE
borneInf = Y_19 - borne
borneSup = Y_19 + borne
plot(X_i, Y_i, main = "Nombre de bactéries en fonction de la température", xlab = "Température en °C", ylab = "Nombre de bactéries")
lines(c(min(X_i), max(X_i), 0.1), borneInf)
X_19 = 19
Y_19 = beta0 + beta1*X_19
SE = sqrt(sigma2 * (1/length(X_i) + (X_19-X_i_barre)^2/sum((X_i-X_i_barre)^2)))
borne = qt(0.95, df = length(X_i)-2)*SE
borneInf = Y_19 - borne
borneSup = Y_19 + borne
plot(X_i, Y_i, main = "Nombre de bactéries en fonction de la température", xlab = "Température en °C", ylab = "Nombre de bactéries")
lines(c(X_19, X_19), c(borneInf, borneSup))
X_19 = 19
Y_19 = beta0 + beta1*X_19
SE = sqrt(sigma2 * (1/length(X_i) + (X_19-X_i_barre)^2/sum((X_i-X_i_barre)^2)))
borne = qt(0.95, df = length(X_i)-2)*SE
borneInf = Y_19 - borne
borneSup = Y_19 + borne
plot(X_i, Y_i, main = "Nombre de bactéries en fonction de la température", xlab = "Température en °C", ylab = "Nombre de bactéries")
abline(h = Y_19, lty = 2, col = "blue")  # Add a horizontal dashed line for the estimated mean at 19°C
abline(v = X_19, lty = 2, col = "green")  # Add a vertical dashed line for the temperature 19°C
abline(v = X_19 - 0.5, lty = 2, col = "purple")  # Add a vertical dashed line for the lower bound of the confidence interval
abline(v = X_19 + 0.5, lty = 2, col = "purple")
X_19 = 19
Y_19 = beta0 + beta1*X_19
SE = sqrt(sigma2 * (1/length(X_i) + (X_19-X_i_barre)^2/sum((X_i-X_i_barre)^2)))
borne = qt(0.95, df = length(X_i)-2)*SE
borneInf = Y_19 - borne
borneSup = Y_19 + borne
plot(X_i, Y_i, main = "Nombre de bactéries en fonction de la température", xlab = "Température en °C", ylab = "Nombre de bactéries")
lines(c(X_19, X_19), c(borneInf, borneSup))
X_19 = 19
Y_19 = beta0 + beta1*X_19
SE = sqrt(sigma2 * (1/length(X_i) + (X_19-X_i_barre)^2/sum((X_i-X_i_barre)^2)))
borne = qt(0.95, df = length(X_i)-2)*SE
borneInf = Y_19 - borne
borneSup = Y_19 + borne
plot(X_i, Y_i, main = "Nombre de bactéries en fonction de la température", xlab = "Température en °C", ylab = "Nombre de bactéries")
lines(c(X_19, X_19), c(borneInf, borneSup))
abline(h = Y_19, lwd =2 )
abline(h = borneInf, lty =2)
abline(h = borneSup, lty =2)
setwd("~/Bureau/Polytech/MAM4/Informatique/SériesTemporelles/TP1")
A=load('data1.RData')
rm(list=ls())
A=load('data1.RData')
A
dim(khct.df)
head(khct.df)
data=khct.df
pairs(data)
Y=sqrt(data$kwh)
B=data.frame(int=rep(1,180),htdd=data$htdd,cldd=data$cldd,t1=data$t1)
#rep(1,180) permet de creer un vecteur ne contenant que des 1 repetes 180 et ensuite on recopie les autres variables
X=as.matrix(B)[1:168,]
Y=matrix(Y[1:168],ncol=1)
inv=solve(t(X)%*%X)
betah=inv%*%t(X)%*%Y
C=B[1:168,]
#pour utiliser la fonction lm, on extrait les donnees jusqu'a l'annee 1983
betahb=lm(Y~htdd+cldd+t1,data=C)
betah
betahb
plot(betahb)
Bb=data.frame(int=rep(1,180),htdd=data$htdd,cldd=data$cldd,t1=data$t1,t2=(data$t1-1977)^2)
Cb=Bb[1:168,]
betah2=lm(Y~htdd+cldd+t1+t2,data=Cb)
Cnew=as.matrix(Bb[169:180,])
#on recupere les donnees des variables explicatives pour l'annee 1984, et on les transforme en une matrice
mod=matrix(data=betah2$coefficients,ncol=1)
pred=Cnew%*%mod
Ynew=sqrt(data$kwh)[169:180]
#puisque l'on parle de 80%, cela signifie que alpha=20% soit alpha=0.2
alpha=0.2
Int=matrix(data=0,ncol=5,nrow=12)
#12 lignes car il y a 12 mois dans une annee
Int[,1]=Ynew
nl=nrow(Cb)
#il nous faut estimer la varaiance du bruit
predl=predict(betah2)
sigma2e=1/(nl-5)*sum((Y-predl)^2)
X=as.matrix(Bb[1:168,])
inv=solve(t(X)%*%X)
for (i in 1:12)
{
Int[i,2]=pred[i,1]-sqrt(sigma2e)*sqrt(matrix(data=Cnew[i,],nrow=1)%*%inv%*%t(matrix(data=Cnew[i,],nrow=1)))*qt(1-alpha/2,nl-5)
Int[i,3]=pred[i,1]+sqrt(sigma2e)*sqrt(matrix(data=Cnew[i,],nrow=1)%*%inv%*%t(matrix(data=Cnew[i,],nrow=1)))*qt(1-alpha/2,nl-5)
Int[i,4]=pred[i,1]-sqrt(sigma2e)*sqrt(1+matrix(data=Cnew[i,],nrow=1)%*%inv%*%t(matrix(data=Cnew[i,],nrow=1)))*qt(1-alpha/2,nl-5)
Int[i,5]=pred[i,1]+sqrt(sigma2e)*sqrt(1+matrix(data=Cnew[i,],nrow=1)%*%inv%*%t(matrix(data=Cnew[i,],nrow=1)))*qt(1-alpha/2,nl-5)
}
#dans la matrice Int, la premiere colonne contient donc les vraies valeurs
#dans la matrice Int, la premiere colonne contient donc les vraies valeurs
#les colonnes 2 et 3 contiennent respectivement les bornes inferieures et superieures de intervalles de confiance pour la moyenne
#dans la matrice Int, la premiere colonne contient donc les vraies valeurs
#les colonnes 2 et 3 contiennent respectivement les bornes inferieures et superieures de intervalles de confiance pour la moyenne
#on peut comparer cela a predict(betah2,newdata=as.data.frame(Cnew),interval='confidence',level=0.8)
#dans la matrice Int, la premiere colonne contient donc les vraies valeurs
#les colonnes 2 et 3 contiennent respectivement les bornes inferieures et superieures de intervalles de confiance pour la moyenne
#on peut comparer cela a predict(betah2,newdata=as.data.frame(Cnew),interval='confidence',level=0.8)
#les colonnes 4 et 5 contiennent respectivement les bornes inferieures et superieures de intervalles de confiance pour la vraie valeur
#en ce qui concerne le trace, cela est bien evidemment impossible car il faudrait pouvoir faire un graphe en dimension 5, ce qui n'est pas possible
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
load("data1.RData")
data = khct.df
pairs(data)
data = data[1:168,]
Y = sqrt(data$kwh)
X1 = data$htdd
X2 = data$cldd
prediction = lm(Y ~ X1 + X2, data = data)
#On récupère les coefficients beta0 et beta1 contenus dans la liste que génère la commande lm
beta0_lm = coef(prediction)[1]
beta1_lm = coef(prediction)[2]
beta2_lm = coef(prediction)[3]
#Calcul du modèle de régression linéaire avec les coefficients obtenus avec lm
y_lm = beta0_lm + beta1_lm*X1 + beta2_lm*X2
plot(data$t1, Y, main = "Régression linéaire multiple la racine du kwh et cldd+htdd", ylab = "KWH", xlab = "Temps en années")
lines(data$t1, y_lm, col = 'red', lwd = 3)
legend("topright", legend = "Régression multiple", col = "red", lwd = 3)
View(khct.df)
data = data[1:168,]
Y = sqrt(data$kwh)
X1 = data$htdd
X2 = data$cldd
X3 = data$t1
X4 = (data$t1-1977)^2
prediction = lm(Y ~ X1 + X2 + X3 + X4, data = data)
#On récupère les coefficients beta0 et beta1 contenus dans la liste que génère la commande lm
beta0_lm = coef(prediction)[1]
beta1_lm = coef(prediction)[2]
beta2_lm = coef(prediction)[3]
beta3_lm = coef(prediction)[4]
beta4_lm = coef(prediction)[5]
#Calcul du modèle de régression linéaire avec les coefficients obtenus avec lm
y_lm = beta0_lm + beta1_lm*X1 + beta2_lm*X2 + beta3_lm*X3 + beta4_lm*X4
plot(data$t1, Y, main = "Régression linéaire multiple la racine du kwh et cldd+htdd+t1+t2=(t1-1977)²", xlab = "Temps en années", ylab = "KWH")
lines(data$t1, y_lm, col = 'lightgreen', lwd = 3)
legend("topright", legend = "Régression multiple", col = "lightgreen", lwd = 3)
# Nombre d'observations
n = length(Y)
# On définit alpha = 0.2 pour avoir un intervalle de confiance à 80%
alpha = 0.2
# Degré de liberté
d = n - length(coef(prediction))
# Quantile de la distribution t
t = qt(1 - alpha / 2, d)
# \hat{\sigma}
hat_sigma = sqrt(sum((Y - y_lm)^2) / (n - 2))
# Calcul des intervalles de confiance
interv = t * hat_sigma * sqrt(1 +
(1/n) +
((X1 - mean(X1))^2 / sum((X1 - mean(X1))^2)) +
((X2 - mean(X2))^2 / sum((X2 - mean(X2))^2)) +
((X3 - mean(X3))^2 / sum((X3 - mean(X3))^2)) +
((X4 - mean(X4))^2 / sum((X4 - mean(X4))^2)))
borneInf = y_lm - interv
borneSup = y_lm + interv
# Tracé du graphique avec l'intervalle de confiance
plot(data$t1, Y, main = "Régression linéaire multiple la racine du kwh et cldd+htdd+t1+t2=(t1-1977)²", xlab = "Temps en mois pour l'année 1984", ylab = "KWH")
lines(data$t1, y_lm, col = 'lightblue', lwd = 3)
lines(data$t1, borneSup, col = 'red', lty = 2)
lines(data$t1, borneInf, col = 'red', lty = 2)
legend("topright", legend = c("Borne supérieure","Régression multiple", "Borne inférieure"), col = c("red", "lightblue", "red"), lwd = c(2, 3, 2), lty = c(2, 1, 2))
rm(list=ls())
load("data1.RData")
data = khct.df
data = data[169:180,]
Y = sqrt(data$kwh)
X1 = data$htdd
X2 = data$cldd
X3 = data$t1
X4 = (data$t1-1977)^2
prediction = lm(Y ~ X1 + X2 + X3 + X4, data = data)
#On récupère les coefficients beta0 et beta1 contenus dans la liste que génère la commande lm
beta0_lm = coef(prediction)[1]
beta1_lm = coef(prediction)[2]
beta2_lm = coef(prediction)[3]
beta3_lm = coef(prediction)[4]
beta4_lm = coef(prediction)[5]
#Calcul du modèle de régression linéaire avec les coefficients obtenus avec lm
y_lm = beta0_lm + beta1_lm*X1 + beta2_lm*X2 + beta3_lm*X3 + beta4_lm*X4
plot(data$t1, Y, main = "Régression linéaire multiple la racine du kwh et cldd+htdd+t1+t2=(t1-1977)²", xlab = "Temps en mois pour l'année 1984", ylab = "KWH")
lines(data$t1, y_lm, col = 'lightblue', lwd = 3)
legend("topright", legend = "Régression multiple", col = "lightblue", lwd = 3)
# Nombre d'observations
n = length(Y)
# On définit alpha = 0.2 pour avoir un intervalle de confiance à 80%
alpha = 0.2
# Degré de liberté
d = n - length(coef(prediction))
# Quantile de la distribution t
t = qt(1 - alpha / 2, d)
# \hat{\sigma}
hat_sigma = sqrt(sum((Y - y_lm)^2) / (n - 2))
# Calcul des intervalles de confiance
interv = t * hat_sigma * sqrt(1 +
(1/n) +
((X1 - mean(X1))^2 / sum((X1 - mean(X1))^2)) +
((X2 - mean(X2))^2 / sum((X2 - mean(X2))^2)) +
((X3 - mean(X3))^2 / sum((X3 - mean(X3))^2)) +
((X4 - mean(X4))^2 / sum((X4 - mean(X4))^2)))
borneInf = y_lm - interv
borneSup = y_lm + interv
# Tracé du graphique avec l'intervalle de confiance
plot(data$t1, Y, main = "Régression linéaire multiple la racine du kwh et cldd+htdd+t1+t2=(t1-1977)²", xlab = "Temps en mois pour l'année 1984", ylab = "KWH")
lines(data$t1, y_lm, col = 'lightblue', lwd = 3)
lines(data$t1, borneSup, col = 'red', lty = 2)
lines(data$t1, borneInf, col = 'red', lty = 2)
legend("topright", legend = c("Borne supérieure","Régression multiple", "Borne inférieure"), col = c("red", "lightblue", "red"), lwd = c(2, 3, 2), lty = c(2, 1, 2))
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
data(AirPassengers)
x <- AirPassengers
logx = log(AirPassengers)
par(mfrow = c(2,1))
plot(AirPassengers, xlab = "Temps en années", ylab = "Total international de passagers moyens par mois", main = "Total international de passagers moyens par mois en fonction du temps")
plot(log(AirPassengers), col ="red", xlab = "Temps en années", ylab = "Transformée logarithmique")
par(mfrow = c(2,1))
plot(AirPassengers, xlab = "Temps en années", ylab = "Total international de passagers moyens par mois", main = "Total international de passagers moyens par mois en fonction du temps")
plot(logx, col ="red", xlab = "Temps en années", ylab = "Transformée logarithmique")
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
# Chargement du jeu de données
ozone = read.table(file = "Dataset_ozone.txt", sep = ";", header = TRUE, dec = ",")
# Attribution des variables réponse et explicatives
Y = ozone$maxO3
X = ozone$T12
#Calcul des moyennes empiriques
X_bar = mean(X)
Y_bar = mean(Y)
#Calcul de beta1 et beta0
beta1_manuel <- sum((X - X_bar) * (Y - Y_bar)) / sum((X - X_bar)^2)
beta0_manuel <- Y_bar - beta1_manuel * X_bar
#Calcul du modèle de régression linéaire
y = beta0_manuel + beta1_manuel*X
plot(X, Y, main = "Régression linéaire entre la valeur maximale d'ozone et la température relevée à 12H", ylab = "Max03 : valeur maximale d'ozone par jour", xlab = "T12 : Température relevée à 12H")
lines(X, y, col = 'red', lwd = 2)
legend("topright", legend = "Droite de régression", col = "red", lwd = 2)
# Attribution des variables réponse et explicatives
Y = ozone$maxO3
X = ozone$T12
#Calcul des moyennes empiriques
X_bar = mean(X)
Y_bar = mean(Y)
#Calcul de beta1 et beta0
beta1_manuel <- sum((X - X_bar) * (Y - Y_bar)) / sum((X - X_bar)^2)
beta0_manuel <- Y_bar - beta1_manuel * X_bar
#Calcul du modèle de régression linéaire
y = beta0_manuel + beta1_manuel*X
plot(X, Y, main = "Régression linéaire entre la valeur maximale d'ozone et la température relevée à 12H", ylab = "Max03 : valeur maximale d'ozone par jour", xlab = "T12 : Température relevée à 12H")
lines(y, col = 'red', lwd = 2)
legend("topright", legend = "Droite de régression", col = "red", lwd = 2)
# Attribution des variables réponse et explicatives
Y = ozone$maxO3
X = ozone$T12
#Calcul des moyennes empiriques
X_bar = mean(X)
Y_bar = mean(Y)
#Calcul de beta1 et beta0
beta1_manuel <- sum((X - X_bar) * (Y - Y_bar)) / sum((X - X_bar)^2)
beta0_manuel <- Y_bar - beta1_manuel * X_bar
#Calcul du modèle de régression linéaire
y = beta0_manuel + beta1_manuel*X
plot(X, Y, main = "Régression linéaire entre la valeur maximale d'ozone et la température relevée à 12H", ylab = "Max03 : valeur maximale d'ozone par jour", xlab = "T12 : Température relevée à 12H")
lines(X, y, col = 'red', lwd = 2)
legend("topright", legend = "Droite de régression", col = "red", lwd = 2)
#Calcul de la régression linéaire à l'aide de la commande lm
prediction = lm(Y ~ X, data = ozone)
#On récupère les coefficients beta0 et beta1 contenus dans la liste que génère la commande lm
beta0_lm = coef(prediction)[1]
beta1_lm = coef(prediction)[2]
#Calcul du modèle de régression linéaire avec les coefficients obtenus avec lm
y_lm = beta0_lm + beta1_lm*X
plot(X, Y, main = "Régression linéaire entre la valeur maximale d'ozone et la température relevée à 12H", ylab = "Max03 : valeur maximale d'ozone par jour", xlab = "T12 : Température relevée à 12H")
lines(X, y_lm, col = 'green', lwd = 2)
legend("topright", legend = "Droite de régression", col = "green", lwd = 2)
a = coef(reg)[2:13]
#On définit x et y
x = AirPassengers
y = log(x)
# On définit la longueur des données
n = length(y)
# On crée un vecteur pour le temps de 1 à n
t = 1:n
# On crée 12 variables s pour les saisonnalités
for(i in 1:12){
# On crée 12 vecteurs vides
su = rep(0, times=12)
# On ajoute 1 en ième position du vecteur s_i
su[i] = 1
s = rep(su,times=12)
# On crée les variables appellées s1, s2, etc...
assign(paste('s', i ,sep=""), s)
}
# On fait la régression linéaire mutliples entre toute les variables précédemment définies (-1 mettre l'or)
reg = lm(y~t + s1+s2+s3+s4+s5+s6+s7+s8+s9+s10+s11+s12-1)
#On définit x et y
x = AirPassengers
y = log(x)
# On définit la longueur des données
n = length(y)
# On crée un vecteur pour le temps de 1 à n
t = 1:n
# On crée 12 variables s pour les saisonnalités
for(i in 1:12){
# On crée 12 vecteurs vides
su = rep(0, times=12)
# On ajoute 1 en ième position du vecteur s_i
su[i] = 1
s = rep(su,times=12)
# On crée les variables appellées s1, s2, etc...
assign(paste('s', i ,sep=""), s)
}
# On fait la régression linéaire mutliples entre toute les variables précédemment définies (-1 mettre l'or)
reg = lm(y~t + s1+s2+s3+s4+s5+s6+s7+s8+s9+s10+s11+s12-1)
a = coef(reg)[2:13]
b = coef(reg)[1]
c = a - mean(a)
y_corrigé = y - c
plot(y, type = "l", col = "blue", xlab = "Temps en années", ylab = "Transformée logarithmique", main = "Série temporelle et Version corrigée")
lines(y_corrigé, col = "green", lwd = 2)
legend("topright", legend = c("Série temporelle", "Version corrigée"), col = c("blue", "green"), lwd = 2:2)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
vect = c(9.8,10.1,8.3,7.9,9.5,7.5,10.6,7.7,8.8,1.5,2.9,7.4,6.2,6.9,7.6,7.9,8.8,7.7,9.0,7.4,8.0,8.3,7.3,7.8)
x = ts(vect)
alpha = 0.8
n = length(x)
xnh_chap = 0
for (i in 1:n) {
xnh_chap = xnh_chap + (1-alpha)*alpha^(n-i)*x[i]
}
vect1 = rep(0, n)
val = 0
for (i in 1:n) {
for (j in 1:i) {
val = (1-alpha)*alpha^(i-j)*x[j]
vect1[i] = vect1[i] + val
}
}
#Exo1
#dans toute la suite, nlus travaillons avec h=0 dans un premier temps car aucune influence de $h$
#1)
x=c(9.8,10.1,8.3,7.9,9.5,7.5,10.6,7.7,8.8,1.5,2.9,7.4,6.2,6.9,7.6,7.9,8.8,7.7,9,7.4,8,8.3,7.3,7.8)
rm(list=ls())
#Exo1
#dans toute la suite, nlus travaillons avec h=0 dans un premier temps car aucune influence de $h$
#1)
x=c(9.8,10.1,8.3,7.9,9.5,7.5,10.6,7.7,8.8,1.5,2.9,7.4,6.2,6.9,7.6,7.9,8.8,7.7,9,7.4,8,8.3,7.3,7.8)
n=length(x)
alpha=0.8
xh=c()
for (i in 1:n)
{
xh=c(xh,(1-alpha)*sum(x[1:i]*alpha^(seq(i-1,0,-1))))
}
xhr=c((1-alpha)*x[1])
for (i in 2:n)
{
new=(1-alpha)*x[i]+alpha*xhr[i-1]
xhr=c(xhr,new)
}
xhr2=c(x[1])
for (i in 2:n)
{
new=(1-alpha)*x[i]+alpha*xhr2[i-1]
xhr2=c(xhr2,new)
}
plot(x,type='l')
lines(xh,col='red')
lines(xhr,col='green')
lines(xhr2,col='blue')
legend(x='bottomleft',col=c('black','red','green','blue'),lwd=c(1,1,1,1),legend=c('donn?es','lissage classique', 'lissage r?cursive, initialisation (1-alpha).x_1','lissage r?cursive, initialisation x_1'),cex=0.6)
#2)
alpha=0.1
xhr1=c(x[1])
for (i in 2:n)
{
new=(1-alpha)*x[i]+alpha*xhr1[i-1]
xhr1=c(xhr1,new)
}
alpha=0.5
xhr5=c(x[1])
for (i in 2:n)
{
new=(1-alpha)*x[i]+alpha*xhr5[i-1]
xhr5=c(xhr5,new)
}
alpha=0.9
xhr9=c(x[1])
for (i in 2:n)
{
new=(1-alpha)*x[i]+alpha*xhr9[i-1]
xhr9=c(xhr9,new)
}
plot(x,type='l')
lines(xhr1,col='red')
lines(xhr5,col='green')
lines(xhr9,col='blue')
legend(x='bottomleft',col=c('black','red','green','blue'),lwd=c(1,1,1,1),legend=c('donn?es',paste(c('pr?vision, alpha='),c(0.1,0.5,0.9),sep='')),cex=0.6)
#3)
err1=sum((x-xhr1)^2)
err5=sum((x-xhr5)^2)
err9=sum((x-xhr9)^2)
#4)
s=floor(0.8*length(x))
app=x[1:s]
val=x[(s+1):n]
plot(x,type='l')
abline(v=s)
lines(c(xhr1[1:s],rep(xhr1[s],n-s)),col='red',type='o',pch=20)
lines(c(xhr5[1:s],rep(xhr5[s],n-s)),col='green',type='o',pch=20)
lines(c(xhr9[1:s],rep(xhr9[s],n-s)),col='blue',type='o',pch=20)
err1=sum((val-xhr1[s])^2)  #xhr1[s] repr?sente la pr?diction ? partir des observations x_1,...,x_s
err5=sum((val-xhr5[s])^2)
err9=sum((val-xhr9[s])^2)
err1=sum((val-xhr1[s])^2)  #xhr1[s] repr?sente la pr?diction ? partir des observations x_1,...,x_s
err5=sum((val-xhr5[s])^2)
err9=sum((val-xhr9[s])^2)
#Ex2
n=150
h=20
